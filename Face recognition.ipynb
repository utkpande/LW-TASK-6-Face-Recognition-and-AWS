{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import smtplib, ssl\n",
    "import config\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email import encoders\n",
    "import pywhatkit\n",
    "from datetime import *\n",
    "import boto3\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Live Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "client=boto3.client('ec2')\n",
    "\n",
    "\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions and this function return the cropped images\n",
    "def create_dataset(img):\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if create_dataset(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(create_dataset(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './dataset/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q') or count == 150: # Press q to quit \n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "# Get the training data we previously made\n",
    "data_path = './dataset/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "my_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "\n",
    "# Let's train our model \n",
    "my_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing photo of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Camera to verify the face...\n"
     ]
    }
   ],
   "source": [
    "#Capturing individual photo to send to the allocated email id.\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret , photo = cap.read()\n",
    "\n",
    "cv2.imwrite(\"pic1.jpg\", photo)\n",
    "cap.release()\n",
    "\n",
    "print(\"Opening Camera to verify the face...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face recognition through Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mail sent successfully\n",
      "In 35 seconds web.whatsapp.com will open and after 20 seconds message will be delivered\n",
      "Whatsapp user notified\n",
      "AWS instance launched\n",
      "EBS Volume launched\n",
      "Getting instance ready in 60 sec to attach the volume\n",
      "AWS instance launched along with the attached volume \n"
     ]
    }
   ],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = my_model.predict(face)\n",
    "        # harry_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        #os.system('sleep 15')\n",
    "        if confidence > 90:\n",
    "            \n",
    "            cv2.putText(image, \"Hey Utkarsh\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            \n",
    "            #os.system(\"chrome https://www.google.com/search?q=vimal+daga\")\n",
    "            #os.system(\"wmplayer   c:\\lw.mp3\")\n",
    "            #os.system('sleep 10')\n",
    "            \n",
    "            sender = os.environ.get('SENDER_EMAIL')\n",
    "            receivers = [os.environ.get('RECIEVER_EMAIL')]\n",
    "            body_of_email = 'Hello, the following person tried to use your device'\n",
    "            \n",
    "            message = MIMEMultipart()\n",
    "            message['Subject'] = 'Face_detected'\n",
    "            message['From'] = sender\n",
    "            message['To'] = ','.join(receivers)\n",
    "\n",
    "            #Adds a csv file as an attachment to the email \n",
    "            part = MIMEBase('application', 'octet-stream')\n",
    "            part.set_payload(open('pic1.jpg', 'rb').read())\n",
    "            encoders.encode_base64(part)\n",
    "            part.add_header('Content-Disposition', 'attachment; filename =\"face.jpg\"')\n",
    "            message.attach(part)\n",
    "            \n",
    "            \n",
    "            smtpObj = smtplib.SMTP(host='smtp.gmail.com', port=587)\n",
    "            smtpObj.starttls()\n",
    "            smtpObj.login(sender, os.environ.get('E_PASS'))\n",
    "            #message = \"\"\"Stage 1 completed!! \"\"\"\n",
    "            smtpObj.sendmail(sender, receivers, message.as_string())\n",
    "            smtpObj.quit()\n",
    "            print(\"Mail sent successfully\")\n",
    "            \n",
    "            \n",
    "            pywhatkit.sendwhatmsg(os.environ.get('WHATSAPP_USER_1'), \"Launching AWS instance with 5GB EBS volume \",datetime.now().hour,datetime.now().minute+1)\n",
    "            print(\"Whatsapp user notified\")\n",
    "            \n",
    "            keyname='keyhadoopNN'\n",
    "            instanceName=\"TESTING_INSTANCE\"\n",
    "            \n",
    "            ebsName=\"TESTING_EBS\"\n",
    "            \n",
    "            instances=client.run_instances(\n",
    "                ImageId='ami-0e306788ff2473ccb',\n",
    "                MinCount=1,\n",
    "                MaxCount=1,\n",
    "                InstanceType='t2.micro',\n",
    "                KeyName='{}'.format(keyname),\n",
    "                Placement={\n",
    "                    'AvailabilityZone': 'ap-south-1a'\n",
    "                          },\n",
    "                TagSpecifications=[\n",
    "                    {\n",
    "                        'ResourceType': 'instance',\n",
    "                        'Tags': [\n",
    "                            {\n",
    "                                'Key': 'Name',\n",
    "                                'Value': '{}'.format(instanceName)\n",
    "                            },\n",
    "                        ]\n",
    "                    },\n",
    "                ],\n",
    "            )\n",
    "            print(\"AWS instance launched\")\n",
    "            instance_id=instances['Instances'][0]['InstanceId']\n",
    "            volumes=client.create_volume(\n",
    "                AvailabilityZone='ap-south-1a',\n",
    "                Size=5,\n",
    "                VolumeType='gp2',\n",
    "                TagSpecifications=[\n",
    "                    {\n",
    "                        'ResourceType': 'volume',\n",
    "                        'Tags': [\n",
    "                            {\n",
    "                                'Key': 'Name',\n",
    "                                'Value': '{}'.format(ebsName)\n",
    "                            },\n",
    "                        ]\n",
    "                    },\n",
    "                ],\n",
    "            )\n",
    "            print(\"EBS Volume launched\")\n",
    "            volume_id=volumes['VolumeId']\n",
    "            print(\"Getting instance ready in 60 sec to attach the volume\")\n",
    "            #os.system('powershell Start-Sleep -m 60000')\n",
    "            time.sleep(60)\n",
    "            response = client.attach_volume(\n",
    "                Device='/dev/sdh',\n",
    "                InstanceId='{}'.format(instance_id),\n",
    "                VolumeId='{}'.format(volume_id),\n",
    "            )\n",
    "            \n",
    "            print(\"AWS instance launched along with the attached volume \")\n",
    "            \n",
    "            break\n",
    "            \n",
    "        elif cv2.waitKey(1)==13:\n",
    "            break\n",
    "         \n",
    "        else:\n",
    "            \n",
    "            cv2.putText(image, \"Face not recognised\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
